{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = pd.read_csv(\"/Users/elsa/Desktop/Bootcamp The Bridge/The_Bridge/Ds_Bootcamp_Elsa/Ejercicios/competicion_kaggle/Competicion_how_am_I_feeling/how-am-i-feeling/train_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        label  id_img               path\n",
       "0       happy   22373    happy/22373.jpg\n",
       "1       happy   21433    happy/21433.jpg\n",
       "2       happy   12418    happy/12418.jpg\n",
       "3       happy   21278    happy/21278.jpg\n",
       "4       happy    8081    happy/08081.jpg\n",
       "...       ...     ...                ...\n",
       "6171  sadness   11346  sadness/11346.jpg\n",
       "6172  sadness    4441  sadness/04441.jpg\n",
       "6173  sadness   15236  sadness/15236.jpg\n",
       "6174  sadness   27361  sadness/27361.jpg\n",
       "6175  sadness   25239  sadness/25239.jpg\n",
       "\n",
       "[6176 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>id_img</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>happy</td>\n      <td>22373</td>\n      <td>happy/22373.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>happy</td>\n      <td>21433</td>\n      <td>happy/21433.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>happy</td>\n      <td>12418</td>\n      <td>happy/12418.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy</td>\n      <td>21278</td>\n      <td>happy/21278.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>happy</td>\n      <td>8081</td>\n      <td>happy/08081.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6171</th>\n      <td>sadness</td>\n      <td>11346</td>\n      <td>sadness/11346.jpg</td>\n    </tr>\n    <tr>\n      <th>6172</th>\n      <td>sadness</td>\n      <td>4441</td>\n      <td>sadness/04441.jpg</td>\n    </tr>\n    <tr>\n      <th>6173</th>\n      <td>sadness</td>\n      <td>15236</td>\n      <td>sadness/15236.jpg</td>\n    </tr>\n    <tr>\n      <th>6174</th>\n      <td>sadness</td>\n      <td>27361</td>\n      <td>sadness/27361.jpg</td>\n    </tr>\n    <tr>\n      <th>6175</th>\n      <td>sadness</td>\n      <td>25239</td>\n      <td>sadness/25239.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>6176 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "####################\n(6176, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convertimos todas las imagenes en un array:\n",
    "X_train = []\n",
    "for elem in to_train.path:\n",
    "    path = \"totrain/totrain/\" + elem\n",
    "    X_train.append(cv2.imread(path))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "#print(X_train)\n",
    "print(\"####################\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6176, 48, 48, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "\n",
    "def grayscale(data, dtype='float32'):\n",
    "    # luma coding weighted average in video systems\n",
    "    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n",
    "    rst = r * data[:, :, :, 0] + g * data[:, :, :, 1] + b * data[:, :, :, 2]\n",
    "    # add channel dimension\n",
    "    rst = np.expand_dims(rst, axis=3)\n",
    "    return rst\n",
    "\n",
    "train_images_grey = grayscale(X_train)\n",
    "train_images_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6176, 48, 48, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "train_images_grey = train_images_grey / 255.0\n",
    "train_images_grey.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# Necesito obtener los labels para poder conseguir y_train\n",
    "lista_label = []\n",
    "for elem in to_train.label:\n",
    "    #lista_label.append(cv2.imread(elem))\n",
    "    lista_label.append(elem)\n",
    "\n",
    "# tomo una posición para que no me imprima toda la lista\n",
    "lista_label[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['happy', 'happy', 'happy', ..., 'sadness', 'sadness', 'sadness'],\n",
       "      dtype='<U7')"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "# 2._ OTRA FORMA DE APLICAR LABELENCODER\n",
    "y_train = np.asarray(lista_label)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# APLICAR LABELENCODER a y_train\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "# train_labels = y_train\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data shape :  (4940, 48, 48, 1) (4940,)\nTesting data shape :  (1236, 48, 48, 1) (1236,)\n"
     ]
    }
   ],
   "source": [
    "# 4-Creamos sets de Entrenamiento y Test, Validación y Preprocesar\n",
    "\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(train_images_grey,y_train,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_19\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_13 (Conv2D)           (None, 46, 46, 8)         80        \n_________________________________________________________________\nmax_pooling2d_13 (MaxPooling (None, 23, 23, 8)         0         \n_________________________________________________________________\ndropout_20 (Dropout)         (None, 23, 23, 8)         0         \n_________________________________________________________________\nflatten_14 (Flatten)         (None, 4232)              0         \n_________________________________________________________________\ndense_41 (Dense)             (None, 32)                135456    \n_________________________________________________________________\ndense_42 (Dense)             (None, 10)                330       \n=================================================================\nTotal params: 135,866\nTrainable params: 135,866\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "INPUT_SHAPE = (48,48,1)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# 1 capa convolutiva con 8 neuronas & 1 MaxPool quedando las dimensiones de la imagen a la mitad\n",
    "model.add(keras.layers.Conv2D(filters=8, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"valid\", input_shape=INPUT_SHAPE))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "#1 dropout 0.25\n",
    "model.add(keras.layers.Dropout(rate=0.25))\n",
    "\n",
    "#1 Flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "#1 dense con 32 neuronas\n",
    "model.add(keras.layers.Dense(units=32, activation=\"relu\"))\n",
    "\n",
    "# 1 dense con 10 (salida)\n",
    "model.add(keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estos son los mejores optimizadores para este modeloo: adam, Ftrl, nadam\n",
    "model.compile(optimizer=\"Ftrl\",\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "193/193 [==============================] - 5s 25ms/step - loss: 0.3845 - accuracy: 0.5311\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 5s 25ms/step - loss: 0.3845 - accuracy: 0.5319\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 5s 27ms/step - loss: 0.3845 - accuracy: 0.5319\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 5s 26ms/step - loss: 0.3845 - accuracy: 0.5319\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 5s 26ms/step - loss: 0.3845 - accuracy: 0.5319\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 5s 27ms/step - loss: 0.3845 - accuracy: 0.5319\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 5s 26ms/step - loss: 0.3845 - accuracy: 0.5319\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 5s 27ms/step - loss: 0.3845 - accuracy: 0.5319\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 5s 28ms/step - loss: 0.3845 - accuracy: 0.5319\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 5s 24ms/step - loss: 0.3845 - accuracy: 0.5319\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images_grey, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "193/193 - 2s - loss: 0.3845 - accuracy: 0.0000e+00\n",
      "\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluar Exactitud\n",
    "test_loss, test_acc = model.evaluate(train_images_grey,  y_train, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc). ### ME HA SIDO IMPOSIBLE CONSEGUIR MAS ACCURACY"
   ]
  },
  {
   "source": [
    "## Aplicamos to_pred & sample submission"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = pd.read_csv(\"/Users/elsa/Desktop/Bootcamp The Bridge/The_Bridge/Ds_Bootcamp_Elsa/Ejercicios/competicion_kaggle/Competicion_how_am_I_feeling/how-am-i-feeling/test_set.csv\"). # to_test = to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id_img               path\n",
       "0      18341  to_pred/18341.jpg\n",
       "1      13176  to_pred/13176.jpg\n",
       "2      23945  to_pred/23945.jpg\n",
       "3      15968  to_pred/15968.jpg\n",
       "4      18382  to_pred/18382.jpg\n",
       "...      ...                ...\n",
       "4112    8966  to_pred/08966.jpg\n",
       "4113   12111  to_pred/12111.jpg\n",
       "4114   16629  to_pred/16629.jpg\n",
       "4115   24322  to_pred/24322.jpg\n",
       "4116   23412  to_pred/23412.jpg\n",
       "\n",
       "[4117 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_img</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18341</td>\n      <td>to_pred/18341.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13176</td>\n      <td>to_pred/13176.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23945</td>\n      <td>to_pred/23945.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15968</td>\n      <td>to_pred/15968.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18382</td>\n      <td>to_pred/18382.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4112</th>\n      <td>8966</td>\n      <td>to_pred/08966.jpg</td>\n    </tr>\n    <tr>\n      <th>4113</th>\n      <td>12111</td>\n      <td>to_pred/12111.jpg</td>\n    </tr>\n    <tr>\n      <th>4114</th>\n      <td>16629</td>\n      <td>to_pred/16629.jpg</td>\n    </tr>\n    <tr>\n      <th>4115</th>\n      <td>24322</td>\n      <td>to_pred/24322.jpg</td>\n    </tr>\n    <tr>\n      <th>4116</th>\n      <td>23412</td>\n      <td>to_pred/23412.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>4117 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "to_test"
   ]
  },
  {
   "source": [
    "#### Aplico todos los pasos que he necesitado para X_train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4117"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "to_predd = []\n",
    "for i,elem in enumerate(to_pred):\n",
    "    to_predd.append(np.argmax(to_pred[i]))\n",
    "len(to_predd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 ... 0 0 0]\n####################\n(4117,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4117"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "# Convertimos todas las imagenes en un array:\n",
    "to_pred = []\n",
    "for elem in to_test.path:\n",
    "    path = \"to_pred/to_pred/\" + elem\n",
    "    to_pred.append(np.argmax(path))\n",
    "\n",
    "to_pred = np.array(to_pred)\n",
    "print(to_pred)\n",
    "print(\"####################\")\n",
    "print(to_pred.shape)\n",
    "len(to_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4117,)"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "to_pred = to_test.path\n",
    "to_pred = np.array(to_pred)\n",
    "to_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO CONSIGO SALIR DE ESTE PASO"
   ]
  },
  {
   "source": [
    "test_images_grey = grayscale(to_pred)\n",
    "test_images_grey.shape"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 177,
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-9e1815bd6b68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_images_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_images_grey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-b42b0b2fd689>\u001b[0m in \u001b[0;36mgrayscale\u001b[0;34m(data, dtype)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# luma coding weighted average in video systems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.59\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# add channel dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_grey = test_images_grey / 255.0"
   ]
  },
  {
   "source": [
    "predictions_submit = model.predict(to_pred)\n",
    "predictions_submit"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "submission = pd.DataFrame({\"id_img\": to_pred[\"0\"], \"label\": predictions_submit})\n",
    "submission"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id_img    label\n",
       "0      18341  sadness\n",
       "1      13176  sadness\n",
       "2      23945    happy\n",
       "3      15968    happy\n",
       "4      18382    happy\n",
       "...      ...      ...\n",
       "4112    8966  sadness\n",
       "4113   12111  sadness\n",
       "4114   16629  sadness\n",
       "4115   24322  sadness\n",
       "4116   23412    happy\n",
       "\n",
       "[4117 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_img</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18341</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13176</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23945</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15968</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18382</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4112</th>\n      <td>8966</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>4113</th>\n      <td>12111</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>4114</th>\n      <td>16629</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>4115</th>\n      <td>24322</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>4116</th>\n      <td>23412</td>\n      <td>happy</td>\n    </tr>\n  </tbody>\n</table>\n<p>4117 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4117, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "source": [
    "if submission.shape == sample.shape:\n",
    "    if submission.columns.all() == sample.columns.all():\n",
    "        if submission.id.all() == sample.id.all():\n",
    "            print(\"you're ready to submit!\")\n",
    "            submission.to_csv(\"to_submit.csv\", index = False)\n",
    "            # ¡¡¡¡¡¡¡ADD INDEX = FALSE!!!!!!!!!"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}